[g√©n√©r√© par g√©mini]

# üî¨ Pr√©diction d'ATP par Deep Learning sur Organo√Ødes D√©riv√©s de Patients

Ce projet s'inscrit dans le cadre du d√©fi "AI in Oncology". L'objectif est de d√©velopper un mod√®le de Deep Learning capable de pr√©dire la quantit√© d'ATP (une mesure de la production d'√©nergie cellulaire) √† partir de vid√©os time-lapse d'organo√Ødes sur 96 heures. Cette pr√©diction permet d'√©valuer la r√©ponse aux m√©dicaments et d'accompagner le d√©veloppement de th√©rapies personnalis√©es en oncologie.

## üìä Le D√©fi des Donn√©es (Multiple Instance Learning)

Le d√©fi technique majeur de ce projet r√©side dans l'h√©t√©rog√©n√©it√© des √©chelles :
* **Entr√©e (Input) :** Le jeu de donn√©es contient 92 632 vid√©os de **cavit√©s** (compos√©es de 8 frames).
* **Sortie (Cible) :** La valeur d'ATP cible est mesur√©e exp√©rimentalement et n'est disponible qu'au niveau du **puits** (well), un puits regroupant un traitement sp√©cifique pour un patient.

Pour r√©soudre ce probl√®me de pr√©diction globale √† partir de donn√©es fragment√©es, ce projet impl√©mente une architecture de **Multiple Instance Learning (MIL) Temporelle**. L'√©valuation finale du mod√®le se fait sur la m√©trique **MAPE** (Mean Absolute Percentage Error).

## üß† Architecture du Mod√®le (`EfficientTransformerMIL`)

Le mod√®le traite les donn√©es sous forme de "sacs" (les puits) contenant des "instances" (les vid√©os de cavit√©s), en extrayant l'information spatiale puis temporelle :

1. **Extraction Spatiale (L'≈íil) :** Un r√©seau `EfficientNet-B0` pr√©-entra√Æn√© analyse chaque frame individuellement. Les premi√®res couches sont gel√©es pour √©viter le sur-apprentissage sur la cohorte d'entra√Ænement (36 patients).
2. **Extraction Temporelle (La M√©moire) :** Un `TransformerEncoder` prend en entr√©e la s√©quence de caract√©ristiques des 4 frames s√©lectionn√©es (0, 2, 5, 7) pour comprendre la dynamique de survie ou de mort de l'organo√Øde.
3. **Agr√©gation (Gated Attention) :** Un m√©canisme d'attention avanc√© (Gated Attention) attribue un poids √† chaque cavit√© du puits selon son importance pr√©dictive.
4. **R√©gression :** Un r√©seau dense final pr√©dit le logarithme de l'ATP global du puits, optimis√© via une `SmoothL1Loss`.

## ‚öôÔ∏è Fonctionnalit√©s du Script

* **Gestion de la M√©moire GPU (Chunking) :** Les images passent dans le r√©seau par paquets (chunks de 32) pour √©viter les erreurs `CUDA Out of Memory`.
* **R√©silience aux Donn√©es :** Int√©gration d'un syst√®me robuste qui rep√®re, ignore et compte les fichiers TIFF corrompus sans faire planter l'entra√Ænement.
* **Data Augmentation :** Application de modifications al√©atoires (Autocontrast, ColorJitter, Rotations, Flips) pour assurer la robustesse du mod√®le.
* **Early Stopping & Scheduler :** R√©duction dynamique du Learning Rate et arr√™t pr√©matur√© pour optimiser la convergence.

## üöÄ Installation & Pr√©requis (via `uv`)

Ce projet utilise **`uv`** pour une gestion ultra-rapide des paquets et de l'environnement virtuel. Assurez-vous d'avoir Python 3.10+ d'install√©.

1. **Cr√©er et activer l'environnement virtuel :**
```bash
uv venv
.venv\Scripts\activate   # Sur Windows
# source .venv/bin/activate  # Sur macOS/Linux
```
Installer PyTorch avec le support CUDA (Indispensable pour le GPU) :
Remarque : Modifiez cu121 selon la version de CUDA support√©e par vos drivers NVIDIA (ex: cu118, cu124).

```Bash
uv pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)
```
Installer le reste des d√©pendances :

```Bash
uv pip install pillow matplotlib tqdm
```
üìÇ Structure des Dossiers
Modifiez les chemins dans la section 0. CONFIGURATION du script pour pointer vers vos dossiers. Le code s'attend √† l'arborescence suivante :

Plaintext
DATASET/
‚îú‚îÄ‚îÄ train/              # 36 patients
‚îÇ   ‚îú‚îÄ‚îÄ CGR0010/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [well_id]_[atp]_[conc]_[date]/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ..._1.tif
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ test/               # 15 patients
‚îÇ   ‚îú‚îÄ‚îÄ CGRXXXX/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [well_id]_[conc]_[date]/


üïπÔ∏è Utilisation
Le comportement du script est contr√¥l√© par trois bool√©ens situ√©s en haut du fichier project_ATP.py. Vous pouvez les activer/d√©sactiver selon vos besoins :


Python
RUN_CV = False             # Lance une validation crois√©e Leave-One-Subject-Out (LOSO)
TRAIN_FULL_MODEL = True    # Entra√Æne le mod√®le de production final sur 100% du jeu d'entra√Ænement
RUN_PREDICTION = True      # Effectue l'inf√©rence sur le dossier Test et g√©n√®re le fichier de soumission
Pour lancer le pipeline dans votre environnement uv :

```Bash
uv run project_ATP.py
# ou simplement : python project_ATP.py
```
üìà R√©sultats et Fichiers G√©n√©r√©s
Selon les options activ√©es, le script g√©n√®re automatiquement :

Les Courbes d'Apprentissage : Des fichiers learning_curve_CGRXXXX.png affichant la MAE (Log) et la MAPE de validation pour suivre la sant√© de l'entra√Ænement.

Les Mod√®les : Les poids du meilleur mod√®le (final_model_production.pth).

Le Fichier de Soumission : Un fichier .csv (par d√©faut submission_ATP.csv) format√© pour l'√©valuation, contenant les valeurs brutes d'ATP pr√©dites (pid, well_id, atp_value_raw).

Rapport de Corruption : Dans la console, un bilan de lecture d√©taillant le pourcentage de fichiers TIFF corrompus rencontr√©s.
